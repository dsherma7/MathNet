{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "eb1c73f7-8b99-4c0a-8cf8-b329fdcb5e42"
    }
   },
   "source": [
    "## Modelling Mathematical Theorems\n",
    "### Goals\n",
    "* Determine if there is a trend among theorems of similar fields of Mathematics\n",
    "* What are the most similar fields of Mathematics\n",
    "* Build a predictive model to determine a field by commonly used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "089d9a99-1b4e-47b8-a99d-7357482abe65"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from urllib2 import Request, urlopen, HTTPError\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from urlparse import urlunparse, urlparse\n",
    "from nltk.corpus import wordnet as wn\n",
    "from matplotlib import pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import scipy.stats as stat\n",
    "from nltk import corpus\n",
    "import plasTeX as tex                                             # For Parsing TeX in Wikipedia \n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "import scipy as sci\n",
    "import numpy as np\n",
    "import wordcloud\n",
    "import nltk\n",
    "import json \n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "requests_cache.install_cache('coll_cache')\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the Theorems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the Math Theorems, we scraped the Wikipedia page <a href=\"https://en.wikipedia.org/wiki/List_of_theorems\">List of Theorems</a>. From here we recognized that there was a standard <tt>mw-content-ltr</tt> class in which the body of each page was located in. The following scapes the List of Theorems page, removes the header and footer, and then builds a data frame by scraping the pages of each of the theorems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "f46b14a8-f6d2-4e2b-a092-9b8324ea8308"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_theorems'\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "sections = soup.find_all('li')\n",
    "sections = sections[37:1152] # Remove Header and Footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "aefcb1a2-78b3-4ea2-9cce-966ebfaa0cd4"
    }
   },
   "outputs": [],
   "source": [
    "theorems = {'Field':[],'Title':[],'Link':[],'Page':[]}\n",
    "for temp in sections:\n",
    "    link = temp.find('a')\n",
    "    cat = temp.find('i')\n",
    "    if (cat == None):\n",
    "        if (re.search(r'\\(.*?\\)',link.get('title')) == None):\n",
    "            cat = ''\n",
    "        else:\n",
    "            cat = re.sub('\\(|\\)','',re.search(r'\\(.*?\\)',link.get('title')).group())\n",
    "    else:\n",
    "        cat = cat.get_text().lower()\n",
    "\n",
    "    try:\n",
    "        html = urlopen(\"https://en.wikipedia.org\"+str(link.get('href')))\n",
    "        page = BeautifulSoup(html,'html.parser')\n",
    "    except HTTPError as e:  \n",
    "        page = e\n",
    "    \n",
    "    if type(page) != HTTPError:\n",
    "        theorems['Field'].append(cat)\n",
    "        theorems['Title'].append(link.get('title'))\n",
    "        theorems['Link'].append(link.get('href'))\n",
    "        theorems['Page'].append(page.find(class_='mw-content-ltr'))\n",
    "    \n",
    "theorems = pd.DataFrame(theorems)\n",
    "theorems.to_csv(\"theorems.txt\",sep=',',encoding='utf-8') # Use encoding because of scraped pages\n",
    "print theorems.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we had the html of each of the theorems, we needed to clean this text substantially in order analyze it. To do this we first replaced any unicode titles with their <tt>string</tt> equivalents, then we trimmed any theorems that were part of obscure fields of Mathematics (for example Lie Algebra, Metric Geometry, or Elliptic Differential Equations).\n",
    "\n",
    "Still, we can't train the the html data as is. First, this data has all the html formatting tags such as <\"p\"> and <\"div\">. Beautiful Soup remove's these by the <tt>.get_text()</tt> function. Second, this is Mathematics and as such it contains a substantial amount of Math in each of the pages. Not only is this math not easily translated into words, it is formatted by the standard <tt>TeX</tt> formatting which looks like <tt>\\forall x \\in \\mathbb{R}<\\tt> to produce $\\forall x \\in \\mathbb{R}$. To fix this we first removed the html formatting with get_text(), then used regular expressions to remove any brakets or other formatting that is present in a standard TeX script. However, this still left the above expression as <tt> forall x in mathbb R </tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "a62b1636-af64-49ef-a581-cc0eccd0bffc"
    }
   },
   "outputs": [],
   "source": [
    "## Clean up the table (get rid of Unicode titles)\n",
    "for field in theorems['Field']:\n",
    "    try:\n",
    "        str(field)\n",
    "    except UnicodeEncodeError as e:\n",
    "        print field\n",
    "theorems['Field'][['quantum theory' in x for x in theorems['Field']]] = 'quantum theory'\n",
    "theorems['Field'][['clebsch' in x for x in theorems['Field']]] = 'clebsch gordan coefficients'\n",
    "theorems['Field'] = [str(x) for x in theorems['Field']]\n",
    "\n",
    "## Trim the data for analysis\n",
    "trimmed = [\" \".join([x for x in page.get_text().split() if re.search('\\{*\\}|\\(*\\)|\\$*\\$|\\(|\\)|\\{|\\}',x) == None]) for page in theorems['Page']]\n",
    "theorems['Trimmed'] = trimmed\n",
    "\n",
    "## Removes Theorems in Categories with only min_cnt entries\n",
    "min_cnt = 4\n",
    "good_fields = list(theorems.groupby('Field').count()[theorems.groupby('Field').count()['Link'] > min_cnt].index) \n",
    "duplicate_theorems = theorems[[(x in good_fields) for x in theorems['Field']]]\n",
    "n = duplicate_theorems.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the extraneous words that were part of the TeX commands, we scraped a LaTeX glossary of commands and added these words to our collection of stopwords (used later for classification and word clouds). This glossary can be found <a href=\"https://en.wikibooks.org/wiki/LaTeX/Command_Glossary\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latexUrl = 'https://en.wikibooks.org/wiki/LaTeX/Command_Glossary'\n",
    "try:\n",
    "    latex_html = urlopen(latexUrl)\n",
    "    soup = BeautifulSoup(latex_html,'html.parser')\n",
    "except HTTPError as e:  \n",
    "    print e\n",
    "tex_words = []\n",
    "bad_chars = r'[\\\\|\\xc2|\\x99|\\xa0|{|}]'\n",
    "for cat in soup.find_all('dl'):\n",
    "    for word in soup.find_all('dt'):\n",
    "        try:\n",
    "            tex_words.append(str(re.sub(bad_chars,'',word.get_text()[1:])).lower())\n",
    "        except UnicodeEncodeError as e:\n",
    "            print word\n",
    "        except IndexError as e:\n",
    "            print word\n",
    "\n",
    "stopwords = ['will','the','and','that','said',\n",
    "             'from','they','their','this','year','ext',\n",
    "             'mathbb','true','false','displaystyle','wikipedia',\n",
    "             'ready','user','mediawiki','mw','value','theorem',\n",
    "             'number','lemma','template','en','k_','cdot','x_',\n",
    "             'pmod','styles','window','gadget','module','a_','rlq',\n",
    "             'edit','system','varphi','mathbf','function','wikimedia',\n",
    "             'scriptstyle','doi','references','mathrm']+tex_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we used the nltk package to build word clouds and bar graphs of the most common words across all theorems in a given field of Mathematics. The following is a few functions used in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer().stem\n",
    "tokenize = nltk.word_tokenize\n",
    "\n",
    "def remove_small(series,min_len = 3):\n",
    "    \"\"\"\n",
    "        Removes any words less than or equal to min_len. Returns\n",
    "        a block of text of all these words to be input into NLTK.\n",
    "    \"\"\"\n",
    "    text = []\n",
    "    [[text.append(y) for y in x.split()] for x in series]\n",
    "    text = pd.DataFrame({'text':text})\n",
    "    return(\" \".join(text.iloc[[len(x)>min_len for x in text['text']]]['text']))\n",
    "\n",
    "def stem(tokens,stemmer = PorterStemmer().stem):\n",
    "    \"\"\"\n",
    "        Calls the nltk PorterStemmer() on a lowercase version \n",
    "        of a list of tokens. \n",
    "    \"\"\"\n",
    "    return [stemmer(w.lower()) for w in tokens] \n",
    "\n",
    "def lemmatize(text,stopwords=['']):\n",
    "    \"\"\"\n",
    "    Extract simple lemmas based on tokenization and stemming\n",
    "    Input: string\n",
    "    Output: list of strings (lemmata)\n",
    "    \"\"\"\n",
    "    #text = remove_small([text],min_len)\n",
    "    return stem([x for x in tokenize(text) if x.lower() not in stopwords])\n",
    "\n",
    "def build_wordcloud(text,stopwords,ax=plt,title=''):\n",
    "    \"\"\"\n",
    "        Helper function for building a wordcloud with appropriate \n",
    "        title and formatting. Also returns the wordcloud as a \n",
    "        data frame of each word and its associated frequency.\n",
    "    \"\"\"\n",
    "    wordcloud = WordCloud(stopwords = stopwords,font_path='/Library/Fonts/Apple Chancery.ttf').generate(text)\n",
    "    ax.imshow(wordcloud)\n",
    "    ax.axis(\"off\")\n",
    "    ax.show() if ax == plt else ''\n",
    "    ax.set_title(title) if ax != plt else ''\n",
    "    words = WordCloud(stopwords = stopwords).process_text(text)\n",
    "    words = pd.DataFrame({'Words':words.keys(),'Freq':words.values()}).sort_values('Freq',ascending=0)    \n",
    "    return(words)\n",
    "\n",
    "def f(text,ax=plt,stopwords=[''],min_len=7,title=None): \n",
    "    \"\"\"\n",
    "       Helper function for build_wordcloud that adds the \n",
    "       title to the list of stopwords and removes and small\n",
    "       words with remove_small first.\n",
    "    \"\"\"\n",
    "    if (title == None):\n",
    "        title = text.iloc[0,0]\n",
    "    texts = [y.lower() for y in text['Trimmed']]\n",
    "    words=build_wordcloud(stopwords=stopwords+title.split(' '),text=remove_small(texts,min_len),ax=ax,title=title)\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then built word clouds and bar graphs of the most common words in each field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "a2cc20c7-f43b-4d04-a948-e54183238ebd"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "min_len = 6\n",
    "grp = duplicate_theorems.groupby('Field')\n",
    "fields = grp.apply(lambda x: x.iloc[0,0])\n",
    "topwords = {}\n",
    "for j in range(int(np.ceil(float(len(grp))/4.0))):\n",
    "#for j in [8,10,13]: # Select theorems of interest\n",
    "    f1,ax1 = plt.subplots(1,4,figsize = [20,10])\n",
    "    f2,ax2 = plt.subplots(1,4,figsize = [20,3])\n",
    "    for i in xrange(4):\n",
    "        field = fields[i+4*j] if i+4*j < len(grp) else fields[-1]\n",
    "        temp = duplicate_theorems[duplicate_theorems['Field']==field]\n",
    "        txt=f(temp,ax1[i],stopwords=stopwords,min_len=min_len)\n",
    "        txt[0:10].set_index('Words').plot(kind='bar',ax=ax2[i],title=field)\n",
    "        topwords[field] = txt        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "943473ac-3b99-4fdd-988f-b1829cd72323"
    }
   },
   "source": [
    "### Similarity of Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we measured the similarity of each field of Mathematics based on each fields most common words. The following builds a dictionary that provides a list of which fields of Math contain the Key in their most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textd = {}                                              # dictionary from lemmata to document ids containing that lemma\n",
    "freqd = {}\n",
    "min_freq = 5\n",
    "for field in topwords.keys():\n",
    "    freqd.update({field:sum(topwords[field]['Freq'][topwords[field]['Freq'] > min_freq].values)})\n",
    "    t = \" \".join(topwords[field]['Words'][topwords[field]['Freq'] > min_freq])    \n",
    "    s = set(lemmatize(t,stopwords))\n",
    "    try:\n",
    "        toks = toks | s\n",
    "    except NameError:\n",
    "        toks = s\n",
    "    for tok in s:\n",
    "        try:\n",
    "            textd[tok].append(field)\n",
    "        except KeyError:\n",
    "            textd[tok] = [field]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary is then turned into a data frame, below shows how many fields have the Keys as part of their top words. Below is a list of the ten most shared words among the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "cc9cf1b5-7caf-45e9-b363-15e0e16c3753"
    }
   },
   "outputs": [],
   "source": [
    "textd_save = textd\n",
    "min_len = 4\n",
    "textd = {key:vals for key,vals in textd_save.items() if len(key) > min_len}\n",
    "print len(textd_save.keys()),len(textd.keys())\n",
    "temp = pd.DataFrame({'Keys':textd.keys(), 'Length':[len(y) for y in textd.values()]}).sort_values('Length',ascending=False)\n",
    "temp[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "aa65fb06-657c-4334-bf11-95e73fb702a1"
    }
   },
   "outputs": [],
   "source": [
    "def get_max_sim(C):\n",
    "    \"\"\"\n",
    "        Returns the df of the most similar articles for a given corpus class. \n",
    "        Also returns a corpus for that df.\n",
    "    \"\"\"\n",
    "    A = C\n",
    "    temp = {'Max':[],'Argmax':[]}\n",
    "    for i in range(A.shape[0]):\n",
    "        temp['Argmax'].append((A.getcol(i)[range(i)+range(i+1,A.shape[0])]).A.argmax())\n",
    "        temp['Max'].append((A.getcol(i)[range(i)+range(i+1,A.shape[0])]).max())\n",
    "    df = pd.DataFrame(temp,index=range(A.shape[0])).sort_values(['Max'],ascending = 0)\n",
    "    df['Field_1'] = np.array(fields)[df.index.values]\n",
    "    df['Field_2'] = np.array(fields)[df['Argmax']]\n",
    "    return(df)\n",
    "\n",
    "def all_combos(seq):\n",
    "    \"\"\"\n",
    "        Given a seq, returns all possible subsets of this sequence,\n",
    "        with length equal to 2 and disregards order.\n",
    "        Ex: all_combos([1,2,3]) = {[1,2],[1,3],[2,3]}\n",
    "    \"\"\"\n",
    "    s = []\n",
    "    for i in range(len(seq)):\n",
    "        for j in range(i+1,len(seq)):\n",
    "            s = s + [[seq[i],seq[j]]]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $n$ total fields and $\\nu$ total words, the similarity matrix for the fields of Mathematics, $Sim = [s_{ij}] \\in \\mathbb{R}^{n\\times n}$, is given by,\n",
    "\n",
    "$$s_{ij} = \\frac{\\sum_{k=1}^\\nu \\gamma_{ij}(w_k) }{\\sqrt{2m_i m_j}};\\quad\\quad \\gamma_{ij} = \\left\\lbrace\n",
    "\\begin{matrix} \n",
    "1&\\text{if}&w_k\\in F_i \\cap F_j \\\\\n",
    "0&\\text{if}&i=j\\\\\n",
    "0&\\text{if}&w_k\\notin F_i\\cap F_j\\\n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "where $F_i$ is the set of words for Field $i$, $w_k$ is the $k$th word, and $\\beta$ is a scaling factor to force $s_{ij}\\in [0,1]$. Below computes that similarity matrix and displays it as a graph of intensity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = max([len(x) for x in textd.values()])\n",
    "combos = {}\n",
    "for i in xrange(n+1):\n",
    "    combos[i] = all_combos(xrange(i)) \n",
    "print {'Max{Fields per Word}:': n}\n",
    "\n",
    "sim = np.zeros([len(fields),len(fields)])\n",
    "field_key = {x[1]:x[0] for x in enumerate(fields)}\n",
    "\n",
    "for key,val in textd.items():\n",
    "    s = combos[len(val)]\n",
    "    for indx in s:\n",
    "        total_freq = np.sqrt(2*float(freqd[val[indx[0]]]+freqd[val[indx[1]]]))\n",
    "        sim[field_key[val[indx[0]]],field_key[val[indx[1]]]] += float(1)/total_freq\n",
    "        sim[field_key[val[indx[1]]],field_key[val[indx[0]]]] += float(1)/total_freq\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sim = pd.DataFrame(sim).rename(index=str,columns={x:y for x,y in enumerate(fields)}).set_index(keys=fields)\n",
    "sns.heatmap(sim, cmap=cmap, vmax=1, cbar = True,\n",
    "            square=True, xticklabels=2, yticklabels=2,\n",
    "            linewidths=.5)\n",
    "\n",
    "\n",
    "max_sim = get_max_sim(sci.sparse.csr_matrix(sim))\n",
    "max_sim[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "106c6114-3571-4c6c-b38d-6193e0ec9e1b"
    }
   },
   "source": [
    "### Classifying Field of Mathematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we built a classifer to predict the field of Mathematics that a theorem belongs to. We tested using bag of words or just the top words of each field with both Multinomial Naive Bayes and SVM models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "137b667d-d3d8-4452-b056-1f337e6d0ec4"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "\n",
    "def performance(true, pred,P=1):\n",
    "    \"\"\"\n",
    "        Computes the True Positive, False Positive, True Negative, \n",
    "        and False Negative of a prediction.\n",
    "    \"\"\"\n",
    "    TP = FP = TN = FN = 0\n",
    "    for x,y in zip(true,pred): \n",
    "        if x==y==P:\n",
    "           TP += 1\n",
    "        if y==P and x!=y:\n",
    "           FP += 1\n",
    "        if y!=P and x==y:\n",
    "           TN += 1\n",
    "        if y!=P and x!=y:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "def test_clf(df,clf,topwords,top_x=15):\n",
    "    \"\"\"\n",
    "        Tests a clf model for a given choice of using the top_x \n",
    "        most common words of a field.\n",
    "    \"\"\"\n",
    "    if topwords != None:\n",
    "        df.data = [\" \".join(topwords[field]['Words'][0:top_x].values) for field in df.target_names]\n",
    "    \n",
    "    indx = range(df.shape[0])\n",
    "    random.shuffle(indx)\n",
    "    trainSz = int(np.floor(0.5*len(indx)))\n",
    "    train_indx, test_indx = indx[:trainSz],indx[trainSz:]\n",
    "    train_thm, test_thm = df.iloc[train_indx,:], df.iloc[test_indx,:]\n",
    "\n",
    "    import sklearn.datasets\n",
    "    train = sklearn.datasets.base.Bunch(\n",
    "                    description=train_thm.description,\n",
    "                    filenames=train_thm.filenames,\n",
    "                    target_names=train_thm.target_names,\n",
    "                    data=train_thm.data,\n",
    "                    target=train_thm.target)\n",
    "\n",
    "    test = sklearn.datasets.base.Bunch(\n",
    "                    description=test_thm.description,\n",
    "                    filenames=test_thm.filenames,\n",
    "                    target_names=test_thm.target_names,\n",
    "                    data=test_thm.data,\n",
    "                    target=test_thm.target)\n",
    "\n",
    "    clf = clf.fit(train.data, train.target)\n",
    "    predicted = clf.predict(test.data)\n",
    "\n",
    "    TP, FP, TN, FN = np.mean([performance(test.target, predicted,i) for i in set(predicted)],axis=0)\n",
    "    acc = np.mean(predicted == test.target)    \n",
    "    sens = TP/(TP+FN) if TP+FN > 0 else float('Inf')\n",
    "    spec = TN/(FP+TN) if FP+TN > 0 else float('Inf')\n",
    "    prec = TP/(TP+FP) if TP+FP > 0 else float('Inf')\n",
    "    fall = FP/(FN+TN) if FN+TN > 0 else float('Inf')\n",
    "    cm = {'Accuracy':acc,'Sensitivity':sens,\n",
    "          'Specificity':spec,'Precision':prec,'Fallout':fall}\n",
    "    return(cm)\n",
    "\n",
    "NB  = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', MultinomialNB()),\n",
    "])\n",
    "SVM = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42)),\n",
    "])\n",
    "new_duplicate = duplicate_theorems.iloc[range(37)+range(38,duplicate_theorems.shape[0]),:].copy()\n",
    "new_duplicate['target'] = [field_key[x] for x in new_duplicate.Field]\n",
    "new_duplicate.columns = ['target_names','filenames','Page','description','data','target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ac0f462c-7c1c-4061-b03a-280e658388aa"
    }
   },
   "source": [
    "#### Fitting Models to Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a bag of words as a feature set we check both the Multinomial Naive Bayes (MNB) and SVM models. The SVM model fits multiple classes in 1 vs all fashion as it is a binary classifier. Hence it checks each Theorem against each field and returns the most likely field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = test_clf(new_duplicate,NB,None)\n",
    "print 'MNB:',{x:round(y,4) for x,y in temp.items()}\n",
    "\n",
    "svm_cm = test_clf(new_duplicate,SVM,None)\n",
    "print 'SVM:',{x:round(y,4) for x,y in svm_cm.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the accuracy was significantly lower than desired, but the SVM model was clearly better than the MNB model. We then tuned the SVM model's hyper-parameters using a grid search in order produce the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_svm = {'alpha':[],'n_iter':[],'rand_state':[] ,'Accuracy':[],'Precision':[],'Sensitivity':[],'Specificity':[]}\n",
    "for alpha in [1e-14,1e-12,1e-10,1e-8,1e-6,1e-4,1e-2]:\n",
    "    for n_iter in [3,8,13,18,23,28,33]:\n",
    "        for rnd in [20,40,60,80]:\n",
    "            SVM = Pipeline([('vect', CountVectorizer()),\n",
    "                            ('tfidf', TfidfTransformer()),\n",
    "                            ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=alpha, n_iter=n_iter, random_state=rnd)),\n",
    "            ])\n",
    "            temp1 = test_clf(new_duplicate,SVM,None)\n",
    "            grid_svm['alpha'].append(alpha)\n",
    "            grid_svm['n_iter'].append(n_iter)\n",
    "            grid_svm['rand_state'].append(rnd)            \n",
    "            grid_svm['Accuracy'].append(temp1['Accuracy'])\n",
    "            grid_svm['Precision'].append(temp1['Precision'])\n",
    "            grid_svm['Sensitivity'].append(temp1['Sensitivity'])\n",
    "            grid_svm['Specificity'].append(temp1['Specificity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_df = pd.DataFrame(grid_svm)\n",
    "grid_df['AdjustedMean'] = grid_df[['Accuracy','Specificity','Sensitivity','Precision']].mean(axis=1).values\n",
    "grid_df.plot(kind='scatter',x='alpha',y='n_iter',c = 'AdjustedMean',logx=True,xlabel='alpha')\n",
    "\n",
    "best_alpha, best_n_iter, best_rnd = grid_df.sort_values('AdjustedMean',ascending = 0)[['alpha','n_iter','rand_state']].iloc[0,:]\n",
    "print {'Best Alpha':best_alpha,'Best Num Iter':best_n_iter,'Best Random State':best_rnd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b8aca5a9-b9cf-48a8-ae01-21a953ffa15a"
    }
   },
   "source": [
    "#### Running Multinomial Naive Bayes on Top Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we tried running the models on just the top words of each field rather than the whole bag of words approach. Since this produces a new hyper-parameter, <tt>top_x</tt>, which dictates how many of the top words are used in the model. Using this hyper-parameter, we built ROC and Precision-Recall curves as well as plotted the accuracy for the various values of <tt>top_x</tt>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_integrate(x,y,step=0.1):\n",
    "    \"\"\"\n",
    "        Computes the area under the curve of a spline \n",
    "        interpolated from x and y over [0,1].\n",
    "    \"\"\"\n",
    "    from scipy.interpolate import spline\n",
    "    # Removes repeated x values for spline interpolation\n",
    "    temp = pd.DataFrame({'x':x,'y':y,'r':[round(t,3) for t in x]}).sort_values('r').groupby('r').mean()\n",
    "    xnew = [float(z)*step for z in range(0,int(float(1)/step))]\n",
    "    f2 = spline(xk=temp['x'], yk=temp['y'], xnew=xnew)\n",
    "    dx = [xnew[i]-xnew[i-1] for i in xrange(1,len(xnew))]\n",
    "    area = sum(dx*f2[1:])\n",
    "    return(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = test_clf(new_duplicate,NB,topwords,15)\n",
    "print {x:round(y,4) for x,y in temp.items()}\n",
    "\n",
    "indx = range(1,40,1)\n",
    "temp1 = [test_clf(new_duplicate,NB,topwords,i) for i in indx]\n",
    "\n",
    "CM = {'Accuracy'   :[x['Accuracy']    for x in temp1],\n",
    "      'Precision'  :[x['Precision']   for x in temp1],\n",
    "      'Sensitivity':[x['Sensitivity'] for x in temp1],\n",
    "      'Specificity':[x['Specificity'] for x in temp1],\n",
    "      'Fallout'    :[x['Fallout']     for x in temp1]}\n",
    "\n",
    "# Plot ROC Curve with y=x line for reference\n",
    "_,ax = plt.subplots(1,3,figsize = [15,5])\n",
    "_=pd.DataFrame(CM).plot(kind = 'scatter',y = 'Precision',x = 'Sensitivity',ax=ax[0],color = 'red',title='ROC Curve')\n",
    "_=pd.DataFrame(CM).plot(kind = 'scatter',y = 'Sensitivity',x = 'Fallout',ax=ax[0],color = 'blue')\n",
    "_=ax[0].legend(labels=['Prec-Recall','ROC']), ax[0].set_xlabel(\"Fallout/Recall\"), ax[0].set_ylabel(\"Sensitivity/Precision\")\n",
    "_=ax[0].plot([0, 1], [0, 1], 'k-', lw=2)\n",
    "area = 'AUC: ' + str(round(my_integrate(x=CM['Sensitivity']+CM['Fallout'],y=CM['Precision']+CM['Sensitivity'],step=0.001),3))\n",
    "plt.text(0.6, 0.2,area, transform=ax[0].transAxes)\n",
    "\n",
    "_=pd.DataFrame(CM['Accuracy']).plot(ax=ax[1],title='Accuracy vs. Top_X',color='blue')\n",
    "ax[1].set_xlabel(\"# of Words Used\"), ax[1].set_ylabel(\"Accuracy\")\n",
    "\n",
    "_=pd.DataFrame(CM['Accuracy']).plot(kind = 'kde',ax=ax[2],title='Accurace KDE',color='blue')\n",
    "ax[2].axvline(x=np.mean(CM['Accuracy']),color='red')\n",
    "ax[2].set_xlabel(\"Accuracy\")\n",
    "ax[2].legend(labels=['Dist','Mean'])\n",
    "\n",
    "\n",
    "print {'Min: ' : str(min(CM['Accuracy'])),\n",
    "       'Max: ' : str(max(CM['Accuracy'])),\n",
    "       'Mean: ' : str(np.mean(CM['Accuracy']))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8633dbc4-8576-4ff6-9f4c-8222469282bb"
    }
   },
   "source": [
    "#### Running SVM on Top Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After determining the best values for <tt> rand_state, n_iter,</tt> and <tt> alpha </tt> we ran the tuned SVM model on just the top words of each field tuning the <tt>top_x</tt> hyper-parameter to build the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SVM = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=best_alpha, n_iter=best_n_iter, random_state=int(best_rnd))),\n",
    "                ])\n",
    "svm_cm = test_clf(new_duplicate,SVM,topwords,15)\n",
    "print {x:round(y,4) for x,y in svm_cm.items()}\n",
    "\n",
    "indx = range(1,40,1)\n",
    "temp1 = [test_clf(new_duplicate,SVM,topwords,i) for i in indx]\n",
    "\n",
    "CM = {'Accuracy'   :[x['Accuracy']    for x in temp1],\n",
    "      'Precision'  :[x['Precision']   for x in temp1],\n",
    "      'Sensitivity':[x['Sensitivity'] for x in temp1],\n",
    "      'Specificity':[x['Specificity'] for x in temp1],\n",
    "      'Fallout'    :[x['Fallout']     for x in temp1]}\n",
    "\n",
    "# Plot ROC Curve with y=x line for reference\n",
    "_,ax = plt.subplots(1,3,figsize = [15,5])\n",
    "_=pd.DataFrame(CM).plot(kind = 'scatter',y = 'Precision',x = 'Sensitivity',ax=ax[0],color = 'red', title='ROC Curve')\n",
    "_=pd.DataFrame(CM).plot(kind = 'scatter',y = 'Sensitivity',x = 'Fallout',ax=ax[0],color = 'blue')\n",
    "_=ax[0].legend(labels=['Prec-Recall','ROC']), ax[0].set_xlabel(\"Fallout/Recall\"), ax[0].set_ylabel(\"Sensitivity/Precision\")\n",
    "_=ax[0].plot([0, 1], [0, 1], 'k-', lw=2)\n",
    "area = 'AUC: ' + str(round(my_integrate(x=CM['Sensitivity']+CM['Fallout'],y=CM['Precision']+CM['Sensitivity'],step=0.001),3))\n",
    "plt.text(0.7, 0.2,area, transform=ax[0].transAxes)\n",
    "\n",
    "_=pd.DataFrame(CM['Accuracy']).plot(ax=ax[1],title='Accuracy vs. Top_X',color='blue')\n",
    "ax[1].set_xlabel(\"# of Words Used\"), ax[1].set_ylabel(\"Accuracy\")\n",
    "\n",
    "_=pd.DataFrame(CM['Accuracy']).plot(kind = 'kde',ax=ax[2],title='Accuracy KDE',color='blue')\n",
    "ax[2].axvline(x=np.mean(CM['Accuracy']),color='red')\n",
    "ax[2].set_xlabel(\"Accuracy\")\n",
    "ax[2].legend(labels=['Dist','Mean'])\n",
    "\n",
    "print {'Min: ' : str(min(CM['Accuracy'])),\n",
    "       'Max: ' : str(max(CM['Accuracy'])),\n",
    "       'Mean: ' : str(np.mean(CM['Accuracy']))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the accuracy and ROC curve are far superior with the topwords SVM model over the MNB model. This could be partly due to the fact that MNB relies on the features (words) being independent from each other which is not necesarily a good assumption. This is because a theorems choice of wording could affect all other words in the Theorem. For example, a linear algebra theorem could discuss a function as a map or an operator depending on if it is a theorem discusses the linearity of functions, a map between two vector spaces, or a Hermitian operator. In all these cases, the theorem should clearly be classified as Linear Algebra but has vastly different wording. The SVM model makes no such assumption, and it quickly weights non-informative features to zero, leaving only the big words playing a role in the classification. This is seen as the accuracy quickly rises to nearly 100% at only about 7 top words while the MNB model needs 27 to get close to the same accuracy. This is also reflected in the area under the ROC curve (AUC). For MNB this is only 0.091, significantly smaller than the ideal 1.0, while the SVM model gets much closer at 0.711. The reason for MNB's low AUC is that recall just never makes it past 20%. The recall, or true positive rate, is very lower for MNB. Since this value is computed of the recall of choosing each class as true, with the remaining set to false, this demonstrates the lack of granularity in the MNB model. For each of these recall calculations, we have only a handful true classes and mostly false classes, so the MNB model simply markes these as true instead of tweaking its weights to handle such a small number of responses. Both models had very lower Fallouts (or false positive rates), thus a misclassifed positive value was very unlikely. This is again most likely due to the 1 vs all method of multi-class classification; it was so unlikely to label anything as true, thus it was even more unlikely to label the wrong sample as true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Most Beautiful Theorems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following an article on the most \"Beautiful\" theorems of Mathematics from <a href=https://www.quora.com/Which-are-the-most-beautiful-mathematical-theorems-and-why target='_blank'>www.quora.com</a>, the following illustrates some traits of all these theorems as a collection. Quora asked people to consider the following when selecting theorems for the list\n",
    "\n",
    "| Category | Description|\n",
    "|----------|------------|\n",
    "|_Generality_ | it is applicable to a wide variety of problems.|\n",
    "|_Succinctness_|  it is expressible simply, in only a few words or equations.|\n",
    "|_Originality_ | it expresses a surprising mathematical insight, or a connection between different areas of mathematics, that had not previously been widely suspected.|\n",
    "|_Significance_ | it represents an important advance in mathematical knowledge, or resolves an important mathematical problem.|\n",
    "|_Potency_ | it stimulates many new areas of mathematical research.|\n",
    "|_Centrality_ | it is used in the proofs of many subsequent theorems.|\n",
    "|_Independence_ | its proof depends on only a small number of previously established theorems, and preferably none.|\n",
    "\n",
    "The theorems that were selected were\n",
    "<center>\n",
    "The Pythagorean Theoem (Geometry, Pythagoras),\n",
    "Euclid's Theorem of the Infinitude of Primes (Number Theory, Euclid), The Minimax Theorem (Game Theory, John von Neumann),The Brouwer Fixed Point Theorem (Topology, Luitzen Brouwer),Cauchy's Residue Theorem (Complex Analysis, Augustin-Louis Cauchy),Fourier's Theorem (Function Theory, Joseph Fourier),The Halting Theorem (Computability Theory, Alan Turing),Gödel's Incompleteness Theorems (Mathematical logic/Metamathematics, Kurt Godel),Schubert's Prime Knot Factorization Theorem (Knot Theory, Horst Schubert),Cantor's Theorem (Set Theory/Transfinite Analysis, Georg Cantor),Fundamental Theorem of Algebra (Algebra)\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this web page, the Theorems and which category they satisfy from the above list are bolded. Thus by scraping the page for the <tt> <\"b\"> </tt> tag we can get the relevant information after trimming the header (first 7 lines). Moreover, to make the theorem titles match the pre-existing data theorems frame, we had to do some serious trimming. This is done be first correcting any spelling errors, i.e. theoem instead of theorem, and stripping trailing white spaces as well as 'The' from each title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Scraping the Theorems and the considerations for each theorem\n",
    "beau_url = 'https://www.quora.com/Which-are-the-most-beautiful-mathematical-theorems-and-why'\n",
    "beau_soup = BeautifulSoup(urlopen(beau_url),'html.parser').find_all('b')[7:]\n",
    "bolded = [x.get_text() for x in beau_soup if x.get_text()!='']\n",
    "beau_thms  = [re.sub('Theorems|Theorem|Theoem','theorem', re.sub(\"The \",'', y)).strip() for y in bolded if re.search('theorem|theoem',y.lower())]\n",
    "beau_terms = [y for y in bolded if re.search('theorem|theoem',y.lower())==None]\n",
    "beau_dic = {x[0]:x[1] for x in zip(beau_thms,beau_terms)}\n",
    "beau_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after trimming the titles, there were still some that were names differently than our data frame. For example, Residue theorem was called Cauchy's Residue theorem. So we had to correct these titles before searching our data frame for their text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trim Dictionary to match title names\n",
    "beau_dic[\"Residue theorem\"] = beau_dic.pop(\"Cauchy's Residue theorem\")\n",
    "beau_dic[\"Euclid's theorem\"] = beau_dic.pop(\"Euclid's theorem of the Infinitude of Primes\")\n",
    "beau_dic[\"Brouwer fixed point theorem\"] = beau_dic.pop(\"Brouwer Fixed Point theorem\")\n",
    "beau_dic[u\"G\\xf6del's incompleteness theorem\"] = beau_dic.pop(u\"G\\xf6del's Incompleteness theorem\")\n",
    "beau_dic[\"Fundamental theorem of algebra\"] = beau_dic.pop(\"theorem (Fundamental theorem of Algebra): Every polynomial [math]p : \\\\mathbb{C} \\\\rightarrow \\\\mathbb{C} [/math] of degree [math] n[/math] has [math] n [/math] roots (counting multiplicity) in [math] \\\\mathbb{C} [/math]\")\n",
    "beau_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fixing the titles we could join this list of Beautiful Theorems with the associated \"reasons\" for being beautiful with our pre-existing data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build a Data frame using the beautiful theorems in duplicate_theorems\n",
    "BeautifulThms = pd.concat([duplicate_theorems[duplicate_theorems['Title'] == x] for x in beau_dic.keys() if x in \" \".join(duplicate_theorems['Title'])])\n",
    "BeautifulThms['Reasons'] = [re.sub('\\\\.','',beau_dic[x]) for x in BeautifulThms['Title']]\n",
    "BeautifulThms[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we plotted the most common words in all the Theorems that are deemed Beautiful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build Wordclouds from all the Reasons\n",
    "f1,axs = plt.subplots(1,2,figsize = [20,5])\n",
    "for label in (axs[1].get_xticklabels() + axs[1].get_yticklabels()):\n",
    "    label.set_fontsize(16)\n",
    "    \n",
    "texts = [str(BeautifulThms[BeautifulThms['Title']==x]['Trimmed'].values) for x in BeautifulThms['Title'].values]\n",
    "temp = pd.DataFrame({'Trimmed':[remove_small([x.lower() for x in (\" \".join(texts)).split() if re.search(\"[0-9]\",str(x))==None],4)]})\n",
    "txt=f(temp,axs[0],stopwords=stopwords+['which','there'],min_len=min_len,title = 'All')\n",
    "_=txt[0:10].set_index('Words').plot(kind='bar',ax=axs[1],title='All',color='blue')\n",
    "_=plt.gcf().subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't much that can be gained from these plots, but one interesting feature is that the word \"proof\" was by far the most common word, nearly doubling second place. This is pretty clear when you consider that a theorem must be proven, but more importantly this didn't show up in the other word clouds. Thus this likely demonstrates that there is minimal similarity between the Beautiful theorems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BeautySim = {'T1':[], 'F1':[],'Key1':[],'T2':[],'F2':[],'Key2':[],'Sim':[],'R1':[],'R2':[]}\n",
    "beauty_Key = {x:field_key[i] for x,i in enumerate(BeautifulThms['Field'])}\n",
    "for cmb in combos[BeautifulThms.shape[0]]:\n",
    "    x,y = cmb\n",
    "    BeautySim['F1'].append(BeautifulThms.Field.values[x])\n",
    "    BeautySim['F2'].append(BeautifulThms.Field.values[y])\n",
    "    BeautySim['T1'].append(BeautifulThms.Title.values[x])\n",
    "    BeautySim['T2'].append(BeautifulThms.Title.values[y])\n",
    "    BeautySim['R1'].append(BeautifulThms.Reasons.values[x])\n",
    "    BeautySim['R2'].append(BeautifulThms.Reasons.values[y])\n",
    "    BeautySim['Key1'].append(beauty_Key[x])\n",
    "    BeautySim['Key2'].append(beauty_Key[y])\n",
    "    BeautySim['Sim'].append(sim[beauty_Key[x],beauty_Key[y]])\n",
    "\n",
    "BeautySim = pd.DataFrame(BeautySim).sort_values('Sim',ascending=0)\n",
    "BeautySim[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the theorems in this class are very similar, such as complex analysis, number theory, and mathematical logic. These fields are considered as part of the backbone of formal mathematics, which could explain why these were selected as \"Most Beautiful\". Moreover, being the backbone, and since _independence_ was a category for selection, these don't rely on pre-existing Mathematics; leaving minimal phrasing for building these theories and making them similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we looked at the most common \"reasons\" for beautfulness among the Theorems. We plotted two sets of plots; one for all the theorems, and one for just the most similar theorems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build Wordclouds from all the Reasons\n",
    "f1,axs = plt.subplots(1,2,figsize=[12,3])\n",
    "temp = pd.DataFrame({'Trimmed':[str(x) for x in BeautifulThms['Reasons'].values]})\n",
    "txt=f(temp,axs[0],stopwords=[],min_len=min_len,title = 'All')\n",
    "_=txt.set_index('Words').plot(kind='bar',ax=axs[1],title='All')\n",
    "\n",
    "# Build Wordclouds from just the top 10 Reasons\n",
    "f1,axs = plt.subplots(1,2,figsize=[12,3])\n",
    "temp = pd.DataFrame({'Trimmed':[str(x) for x in (BeautySim['R1']+','+BeautySim['R2']).values[0:5]]})\n",
    "txt=f(temp,axs[0],stopwords=[],min_len=min_len,title = 'Top 5')\n",
    "_=txt.set_index('Words').plot(kind='bar',ax=axs[1],title='Top 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There weren't many words to begin with, but there is a clear divide between the two sets as far as distributions go. For the second plot, significance started to play a much larger role than in the first. Moreover, originality fell from importance in the most similar categories. This makes sense, since if they were too original, they wouldn't be labeled as similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then used our trained SVM model to learn more about the beautiful theorems. First we checked the accuracy of the model in correctly predicting their fields, and then we checked what field of Mathematics would be predicted by combining all the beautiful theorems into one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "beauty_df = BeautifulThms.copy()\n",
    "beauty_df['target'] = [field_key[x] for x in BeautifulThms.Field]\n",
    "beauty_df.columns = ['target_names','filenames','Page','description','data','Reasons','target']\n",
    "\n",
    "beauty_test = sklearn.datasets.base.Bunch(\n",
    "                    description=beauty_df.description,\n",
    "                    filenames=beauty_df.filenames,\n",
    "                    target_names=beauty_df.target_names,\n",
    "                    data=beauty_df.data,\n",
    "                    target=beauty_df.target)\n",
    "\n",
    "## Train on all the data\n",
    "train = sklearn.datasets.base.Bunch(\n",
    "                description=new_duplicate.description,\n",
    "                filenames=new_duplicate.filenames,\n",
    "                target_names=new_duplicate.target_names,\n",
    "                data=new_duplicate.data,\n",
    "                target=new_duplicate.target)\n",
    "\n",
    "clf = SVM.fit(train.data, train.target)\n",
    "predicted = clf.predict(beauty_test.data)\n",
    "\n",
    "TP, FP, TN, FN = np.mean([performance(beauty_test.target, predicted,i) for i in set(predicted)],axis=0)\n",
    "acc = np.mean(predicted == beauty_test.target)    \n",
    "sens = TP/(TP+FN) if TP+FN > 0 else float('Inf')\n",
    "spec = TN/(FP+TN) if FP+TN > 0 else float('Inf')\n",
    "prec = TP/(TP+FP) if TP+FP > 0 else float('Inf')\n",
    "cm = {'Accuracy':acc,'Sensitivity':sens,\n",
    "      'Specificity':spec,'Precision':prec}\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here wee see that the accuracy, precision, sensitivity, and specificity are all much less than the mean accuracy for the SVM model. This could be because there is a distinct difference between these \"Beautiful\" theorems and the standard formulaic theorems as a whole. Succinctness and originality were both categories in this list and both of these play against our model by not providing enough words and not providing similar words compared to other theorems in their respective fields. Moreover, theorems like the Fundamental Theorem of Algebra are about Algebra, but because these are the building blocks for Algebra all the algebraic tools built from them, so it requires the use of arithmetic and number theory in their proofs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Classify all the Beauty Theorems into one\n",
    "beauty_all = sklearn.datasets.base.Bunch(\n",
    "                    description=\"All Beautiful\",\n",
    "                    filenames=\"\",\n",
    "                    target_names=\"All\",\n",
    "                    data=[\" \".join(beauty_df.data)],\n",
    "                    target=-1)\n",
    "predicted = clf.predict(beauty_all.data)\n",
    "{x:y for x,y in enumerate(fields) if x == predicted}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the overarching field that most represents all the Beautiful theorems as a whole in Mathematical Logic. Fitting as all of Mathematics pulls from this field. Hence, Mathematical logic would likely be a strong contender in a more subjective classification of the most beautiful theorems. Moreover, Mathematical Logic the independence reason for selecting a Beautiful Theorem leaves mathematical logic as the most likely field to pull from as it is the foundation of all other mathematics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Categorizing Odd Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pre-processing step, we removed any theorems that were a part of some obscure field of Mathematics (per Wikipedia). The following will try to re-classify those Theorems into more appropriate fields so that they can be included with their fellow theorems. For example the field Quantum Theory really should be lumped in with Physics, and 'Several Complex Variables' is just Complex Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "removed_fields = [x for x in theorems['Field'].unique() if x not in duplicate_theorems['Field'].unique()]\n",
    "removed_thms = theorems[[x in removed_fields for x in theorems['Field']]]\n",
    "removed_thms[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "removed_df = removed_thms.copy()\n",
    "removed_df.columns = ['target_names','filenames','Page','description','data']\n",
    "\n",
    "removed_test = sklearn.datasets.base.Bunch(\n",
    "                    description=removed_df.description,\n",
    "                    filenames=removed_df.filenames,\n",
    "                    target_names=removed_df.target_names,\n",
    "                    data=removed_df.data,\n",
    "                    target=removed_df.target_names)\n",
    "\n",
    "predicted = clf.predict(removed_test.data)\n",
    "removed_thms.loc[:,'Predicted'] = [fields[x] for x in predicted]\n",
    "removed_thms[['Field','Predicted']][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above we see that the predicted fields sometimes do not agree with what we would guess subjectively. It is not surprising that  subjects like Lie Algebra, Queuing Theory, and Mathematical Series get predicted as Abstract Algebra, Stochastic Processes, and Analysis respectively. However, the classification of fields like Axiom of Choice, Neural Networks, and Quadratic Forms as Model Theory, Partial Differential Equations, and Number Theory, didn't agree with our first guesses of their parent fields. This is a demonstration that this isn't a classification of the field itself, but the theorem that Wikipedia classified as that original field. For example the Neural Network theorem was the \"Universal approximation theorem\" which describes \n",
    "\n",
    ">\"In the mathematical theory of artificial neural networks, the universal approximation theorem states[1] that a feed-forward network with a single hidden layer containing a finite number of neurons (i.e., a multilayer perceptron), can approximate continuous functions on compact subsets of $\\mathbb{R}^n$, under mild assumptions on the activation function. The theorem thus states that simple neural networks can represent a wide variety of interesting functions when given appropriate parameters; however, it does not touch upon the algorithmic learnability of those parameters.\n",
    "\n",
    ">One of the first versions of the theorem was proved by George Cybenko in 1989 for sigmoid activation functions.[2]\n",
    "\n",
    ">Kurt Hornik showed in 1991[3] that it is not the specific choice of the activation function, but rather the multilayer feedforward architecture itself which gives neural networks the potential of being universal approximators. The output units are always assumed to be linear. For notational convenience, only the single output case will be shown. The general case can easily be deduced from the single output case.\"          \n",
    "~<a href=\"https://en.wikipedia.org/wiki/Universal_approximation_theorem\">Universal Approximation Theorem</a>\n",
    "\n",
    "Now the wording of this quote starts to provide insight into why this was classifed as a PDE theorem. This provides some valuable uses for this prediction algorithm. First of all, the publisher of these Theorems only thought of the single use of the intended Theorem, and using this prediction model we can find other fields of Mathematics that these Theorems support. Moreover, if someone studies a very specific Mathematical idea, by predicting which Field this falls under, it opens up a source for other similar ideas under that field. Under the same idea, this allows publishers of Mathematics papers to consider who else might be interested. For example, the Neural Networks researcher would realize that PDE researchers might be interested and publish in an appropriate journal to reach them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thank you for exploring this Jupyter Notebook! Please contact <a href=\"mailto:desherman@ucdavis.edu?subject=Your%20Awesome%20MathNet%20Project\">Doug Sherman</a> with any questions or comments."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python2]",
   "language": "python",
   "name": "conda-env-Python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nbpresent": {
   "slides": {
    "16bf5572-fd04-471d-9dc5-ce583ecb9ad8": {
     "id": "16bf5572-fd04-471d-9dc5-ce583ecb9ad8",
     "layout": "manual",
     "prev": "4d173b28-57b4-40e3-9358-2038efd39972",
     "regions": {
      "d7c5f101-253c-4df7-b39e-d048318660e6": {
       "attrs": {
        "height": 0.8149081720823308,
        "width": 0.9544619422572176,
        "x": 0.020774278215223152,
        "y": 0.07881598133566643
       },
       "content": {
        "cell": "50b71598-62a4-4a05-a3bb-cc4aafd6f5a5",
        "part": "outputs"
       },
       "id": "d7c5f101-253c-4df7-b39e-d048318660e6",
       "width": 1.65
      }
     },
     "theme": null
    },
    "4d173b28-57b4-40e3-9358-2038efd39972": {
     "id": "4d173b28-57b4-40e3-9358-2038efd39972",
     "prev": "58acbffe-1e03-4708-91c9-1a7b04143302",
     "regions": {
      "a9afd0be-418d-417d-801e-0538904d8c1b": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "9c21ea61-5e0f-4061-9e1e-0e7c0dacff63",
        "part": "outputs"
       },
       "id": "a9afd0be-418d-417d-801e-0538904d8c1b"
      }
     }
    },
    "57eabbcf-0add-422d-a158-d5f3e25580e3": {
     "id": "57eabbcf-0add-422d-a158-d5f3e25580e3",
     "prev": "16bf5572-fd04-471d-9dc5-ce583ecb9ad8",
     "regions": {
      "91710ce4-662b-48cd-b0a0-0310fa5bcc1c": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "879e644c-df7f-4c32-b2cc-01265afa143c",
        "part": "source"
       },
       "id": "91710ce4-662b-48cd-b0a0-0310fa5bcc1c"
      }
     }
    },
    "58acbffe-1e03-4708-91c9-1a7b04143302": {
     "id": "58acbffe-1e03-4708-91c9-1a7b04143302",
     "prev": null,
     "regions": {
      "048a08e6-8912-4ee8-8fcf-56417c32605d": {
       "attrs": {
        "height": 0.9303703703703704,
        "width": 0.95,
        "x": 0.023333333333333334,
        "y": 0.028888888888888888
       },
       "content": {
        "cell": "eb1c73f7-8b99-4c0a-8cf8-b329fdcb5e42",
        "part": "source"
       },
       "id": "048a08e6-8912-4ee8-8fcf-56417c32605d"
      }
     }
    }
   },
   "themes": {
    "default": "dc6078bd-7a9d-41c0-a4d7-448dc4e66062",
    "theme": {
     "dc6078bd-7a9d-41c0-a4d7-448dc4e66062": {
      "id": "dc6078bd-7a9d-41c0-a4d7-448dc4e66062",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         155,
         177,
         192
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410"
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 8
       },
       "h2": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "font-family": "Merriweather",
       "font-size": 4
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
